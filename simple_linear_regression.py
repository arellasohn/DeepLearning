# -*- coding: utf-8 -*-
"""simple linear regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f_tQ6eX7QL6VLlwRHBPP7DGQC30PDAA8
"""

# 수학 라이브러리
import numpy as np

# 데이터 라이브러리
import pandas as pd

# 차트 라이브러리
import matplotlib.pyplot as plt

"""# Data Load"""

# pandas의 read_csv를 이용하여 data를 로드함

# read_csv(file.csv): file.csv를 로드한 후, DataFrame(pandas에서 데이터를 저장하는 형식)을 반환함
dataset = pd.read_csv('Salary_Data.csv')
dataset

"""- X(YearsExperience, 경력)을 입력으로 하여 y(Salary, 연봉)을 예측하는 Linear regression model을 생성한다.

# 2. Dataset을 numpy의 ndarray 형태로 변경
"""

print(type(dataset))

"""- dataset은 DataFrame 타입으로 값(value)뿐만 아니라 column(열) 이름, 각 row(행) 이름 또는 index를 가지고 있다.
- 실제로 우리가 machine learning에서 활용할 경우, 각 값(value) 외에 column이나 row의 정보는 필요 없다.
- numpy의 ndarray는 value 정보만 가지고 있다.
- DataFrame.values는 DataFrame의 value만 가져오며, 타입이 ndarray이다.
"""

# dataset의 column 목록
print(dataset.columns)

# column과 row를 제외한 dataset의 값만 ndarray로 반환함
print(dataset.values)

"""- 여기서 우리는 ndarray를 통해 model을 생성할 예정이므로 dataset.value를 이용한다."""

# dataset DataFrame의 value만 가져와서 arr_data라는 ndarray에 저장함
arr_data = dataset.values

# ndarray.shape은 행과 열의 수를 반환함
print(arr_data.shape)

"""- arr_data.shape은 (30, 2)이며, 30개의 행, 2개의 열로 구성되어 있다는 의미이다,

# 3. X와 y의 분리

- arr_data는 X와 y를 모두 포함하고 있다.
- arr_data에서 첫 번째 열(YearsExperience)은 X로, 두 번째 열(Salary)는 y로 사용한다.
- YearExperience로 Salary를 예측하는 linear regression model을 생성한다.
"""

# indexing: index를 사용해서 특정 위치의 값을 가져옴
# arr_data의 4번째 행, 2번째 열의 값을 확인
# index는 항상 0부터 시작함
print(arr_data[3, 1])

# slicing: index의 범위를 사용해서 특정 영역의 값을 가져옴
# X: arr_data의 전체 행, 첫 번째 열
# y: arr_data의 전체 행, 두 번째(마지막) 열
# 범위 표기 방법
# - a:b -> index a부터 index b-1까지 ex> 1:4 -> 1, 2, 3 index
# - a: -> index a부터 끝까지 ex> 1: -> 1부터 마지막 index까지 포함
# - :b -> 처음부터(index=0) index b-1까지 ex> :4 -> 0, 1, 2, 3
# - : -> (a와 b 모두 생략) 전체 index
X = arr_data[:, 0]
y = arr_data[:, 1]

# ndarray.shape을 했을 때, 반환하는 값의 수는 ndarray의 차원을 의미함
# ex> (30, 1): 2D array, (30,): 1D array, (1, 30): 2D array
print(X.shape, y.shape)

# arr_data[:, 0], arr_data[:, 1]로 ndarray를 slicing하면 1D array가 됨
# 그러나, sklearn package에서 X는 반드시 2D array만 허용됨(y는 1D array 가능)

print(y)

# 2D array data를 가정
# data[index, index] -> 0D array(스칼라)
# data[범위, index] or data[index, 범위]-> 1D array
# data[범위, 범위] -> 2D array
# -> dataset[범위, 범위]로 X를 추출함
X = arr_data[:, 0:1]

# 0:1은 index 0부터 index 1-1까지이므로 index 0만 해당됨
print(X.shape, arr_data[:, 0].shape)
print(X.ndim, arr_data[:, 0].ndim)
print(X)
print(arr_data[:, 0])

# arr_data[:, 0:1]은 arr_data[:, :1]과 동일함
# ndarray에서 전체 크기와 관계 없이 마지막 index는 -1로 대체될 수 있음
# arr_data의 경우, 2개의 column으로 구성되어 있으므로,
# 1이 column에 대해 마지막 index이며, 이는 -1로 대체될 수 있음
# 그러므로 arr_data[:, 0:1] -> arr_data[:, :1] -> arr_data[:, :-1]은 모두 동일함

# ex> shape이 (100, 9)인 dataset의 X는 1번째 column부터 8번째 column까지에 해당한다면
# -> X = dataset[:, 0:8] -> X = dataset[:, :-1]
X = arr_data[:, :-1]
y = arr_data[:, -1]

# X는 반드시 2D array를 사용하고,
# y는 주로 1D array를 사용함
print(X.shape, y.shape)

"""# 4. 학습/테스트 데이터 분리

- 학습 데이터란 학습에 사용되는 데이터를 의미하며, 테스트 데이터는 생성된 모델의 성능을 평가하기 위한 학습에 사용되지 않은 데이터이다.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# train_test_split(data1, data2, test_size, random_state)
# data1, data2: 학습과 테스트로 분리할 데이터(data는 하나만 입력해도 무방함)
# test_sizez: 테스트로 사용할 데이터의 비율
# -> test_size=0.2: 전체 데이터에 대해 20%를 테스트에 사용
# random_state: train_test_split은 기본적으로 데이터를 shuffle한 후 추출하는데,
# 이때 random_state를 하나의 정수로 고정한 상태로 반복적으로 실행하면 항상 동일한 분리 결과가 나옴

# train_test_split(data1, data2, test_size, random_state)의 결과는
# data1의 학습데이터, data2의 학습데이터, data1의 테스트데이터, data2의 테스트데이터
# 순으로 반환됨(반드시 순서에 유의할 것)
print(X_test)